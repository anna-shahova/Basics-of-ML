{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[4. 1. 1.]\n",
      " [6. 2. 2.]\n",
      " [3. 0. 6.]]\n",
      "\n",
      "Accuracy:  0.48\n",
      "Macro Avg Precision:  0.547008547008547\n",
      "Macro Avg Recall:  0.5111111111111111\n",
      "Macro Avg F1 Score:  0.46513720197930725\n",
      "Weighted Avg Precision:  0.5805128205128205\n",
      "Weighted Avg Recall:  0.48\n",
      "Weighted Avg F1 Score:  0.46412955465587047\n",
      "Precision for each class:  [0.30769231 0.66666667 0.66666667]\n",
      "Recall for each class:  [0.66666667 0.2        0.66666667]\n",
      "F1Score for each class:  [0.42105263 0.30769231 0.66666667]\n",
      "Support for each class: [ 6. 10.  9.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "C=\"Cat\"\n",
    "F=\"Fish\"\n",
    "H=\"Hen\"\n",
    "y_true = [C,C,C,C,C,C, F,F,F,F,F,F,F,F,F,F, H,H,H,H,H,H,H,H,H]\n",
    "y_pred = [C,C,C,C,H,F, C,C,C,C,C,C,H,H,F,F, C,C,C,H,H,H,H,H,H]\n",
    "\n",
    "mapping = {C:0, F:1, H:2} # Mapping your classes to numeric values\n",
    "confusion_matrix = np.zeros((3, 3))\n",
    "total_correct = 0\n",
    "\n",
    "for t, p in zip(y_true, y_pred):\n",
    "    confusion_matrix[mapping[t], mapping[p]] += 1\n",
    "    if t == p:\n",
    "        total_correct += 1\n",
    "\n",
    "macro_precision = np.zeros(3)\n",
    "macro_recall = np.zeros(3)\n",
    "macro_f1score = np.zeros(3)\n",
    "support = np.zeros(3)\n",
    "\n",
    "for i in range(3):\n",
    "    macro_precision[i] = confusion_matrix[i, i] / confusion_matrix[:, i].sum()\n",
    "    macro_recall[i] = confusion_matrix[i, i] / confusion_matrix[i, :].sum()\n",
    "    support[i] = confusion_matrix[i, :].sum()\n",
    "    macro_f1score[i] = 2 * ((macro_precision[i] * macro_recall[i]) / (macro_precision[i] + macro_recall[i]))\n",
    "\n",
    "macro_avg_precision = np.mean(macro_precision)\n",
    "macro_avg_recall = np.mean(macro_recall)\n",
    "macro_avg_f1_score = np.mean(macro_f1score)\n",
    "weighted_avg_precision = np.dot(macro_precision, support) / np.sum(support)\n",
    "weighted_avg_recall = np.dot(macro_recall, support) / np.sum(support)\n",
    "weighted_avg_f1_score = np.dot(macro_f1score, support) / np.sum(support)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix)\n",
    "print()\n",
    "print('Accuracy: ', total_correct / len(y_true))\n",
    "print('Macro Avg Precision: ', macro_avg_precision)\n",
    "print('Macro Avg Recall: ', macro_avg_recall)\n",
    "print('Macro Avg F1 Score: ', macro_avg_f1_score)\n",
    "print('Weighted Avg Precision: ', weighted_avg_precision)\n",
    "print('Weighted Avg Recall: ', weighted_avg_recall)\n",
    "print('Weighted Avg F1 Score: ', weighted_avg_f1_score)\n",
    "print('Precision for each class: ', macro_precision)\n",
    "print('Recall for each class: ', macro_recall)\n",
    "print('F1Score for each class: ', macro_f1score)\n",
    "print('Support for each class:', support)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
